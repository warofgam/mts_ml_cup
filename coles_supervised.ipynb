{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "7af790b9-f4cc-40e0-a28a-7f11fc403b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9d6b6b-7a15-4158-8977-ed5c1ec5a3da",
   "metadata": {},
   "source": [
    "### Pretrain datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "9604e3d9-1c92-4c3b-b799-698a1e7cb026",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:21<00:00,  5.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 30.6 s, sys: 16.8 s, total: 47.4 s\n",
      "Wall time: 45.6 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import tqdm, torch\n",
    "\n",
    "df_trans = pq.read_table('data/trans_filtered_pretrained.parquet').to_pandas()\n",
    "\n",
    "cols = ['url_host', 'request_cnt', 'part_of_day', 'event_time']\n",
    "\n",
    "for col in tqdm.tqdm(cols):\n",
    "    df_trans[col] = df_trans[col].apply(torch.tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "95cc6844-bc05-4e19-9306-095b09e51e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trans = df_trans.drop('price', axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "27f15b18-6387-4ec9-9416-ab491a6c8f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "import bisect\n",
    "\n",
    "def age_bucket(x):\n",
    "    return bisect.bisect_left([18,25,35,45,55,65], x)\n",
    "\n",
    "df_public = pq.read_table('data/public_train.pqt').to_pandas().sort_values(by='user_id')\n",
    "\n",
    "# Combined target age_gender\n",
    "df_public['age'] = list(map(age_bucket, df_public['age'] ))\n",
    "df_public = df_public[(df_public['age'] != 'NA') & (df_public['is_male'] != 'NA')]\n",
    "df_public = df_public.dropna()\n",
    "df_public['target'] = df_public['age'].astype(int) + 7 * df_public['is_male'].astype(int)\n",
    "\n",
    "# Merge\n",
    "df_supervised = df_trans.merge(df_public[['user_id', 'target']], on='user_id')\n",
    "\n",
    "train_ft, valid_ft = train_test_split(df_supervised, test_size = 0.3, random_state = 42)\n",
    "\n",
    "train_ft = train_ft.to_dict(orient='records')\n",
    "valid_ft = valid_ft.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "39b04931-64ba-4817-9cba-a124c5382ff7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(237893, 26433)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train_trans), len(df_valid_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "c5211d80-3829-4a01-ab67-aa19d5f0f6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "embedding_matrix = pd.read_pickle('artifacts/url_host_96.pickle').embeddings\n",
    "url_embeddings = torch.nn.Embedding.from_pretrained(torch.Tensor(embedding_matrix), freeze=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f223e8d-dfde-4c4b-9c71-6cf3c744c0a9",
   "metadata": {},
   "source": [
    "## Train COLES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82cc0f45-6d4c-4026-ab33-bb58d1c5a5c7",
   "metadata": {},
   "source": [
    "### Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "a491a9e2-62f6-41f8-9010-0cec157dbded",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ptls.data_load.datasets import MemoryMapDataset\n",
    "from ptls.frames.supervised import SeqToTargetDataset\n",
    "from ptls.frames import PtlsDataModule\n",
    "from ptls.data_load.iterable_processing import SeqLenFilter\n",
    "\n",
    "from ptls.data_load.augmentations import AllTimeShuffle, DropoutTrx, RandomSlice\n",
    "from  ptls.data_load.datasets import AugmentationDataset\n",
    "\n",
    "\n",
    "def get_dataset(data, aug=False):\n",
    "    ds = MemoryMapDataset(data=data, i_filters=[SeqLenFilter(max_seq_len=1000),])\n",
    "    if aug:\n",
    "        ds = AugmentationDataset(ds, f_augmentations = [RandomSlice(10, 500)])\n",
    "    return SeqToTargetDataset(ds, target_col_name='target',)\n",
    "\n",
    "supervised_dm = PtlsDataModule(\n",
    "    train_data=get_dataset(train_ft, aug=True),\n",
    "    valid_data=get_dataset(valid_ft),\n",
    "    train_num_workers=4,\n",
    "    train_batch_size=128,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c351fd-524a-4c32-a394-a679734d92dc",
   "metadata": {},
   "source": [
    "### Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "29cc9c95-79be-4f45-b48e-a48c2712e5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from functools import partial\n",
    "from ptls.nn import TrxEncoder, RnnSeqEncoder\n",
    "from ptls.frames.coles import CoLESModule\n",
    "import ptls\n",
    "\n",
    "trx_encoder_params = dict(\n",
    "    embeddings_noise=0.003,\n",
    "    numeric_values={'request_cnt': 'identity'\n",
    "    },\n",
    "    embeddings={\n",
    "        #'price': {'in': 10, 'out': 2},\n",
    "        #'region_name': {'in': 81, 'out': 4},\n",
    "        #'city_name': {'in': 985, 'out': 16},\n",
    "        #'cpe_manufacturer_name': {'in': 37, 'out': 4},\n",
    "        #'cpe_model_name': {'in': 599, 'out': 16},\n",
    "        #'cpe_type_cd': {'in': 4, 'out': 2}, \n",
    "        #'cpe_model_os_type': {'in': 3, 'out': 2}, \n",
    "        'part_of_day': {'in': 4, 'out': 1},\n",
    "        'url_host': url_embeddings\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "seq_encoder = RnnSeqEncoder(\n",
    "    trx_encoder=TrxEncoder(**trx_encoder_params),\n",
    "    hidden_size=1024,\n",
    "    num_layers=2,\n",
    "    type='gru',\n",
    ")\n",
    "\n",
    "model = CoLESModule(\n",
    "    seq_encoder=seq_encoder,\n",
    "    optimizer_partial=partial(torch.optim.Adam, lr=0.01),\n",
    "    lr_scheduler_partial=partial(torch.optim.lr_scheduler.StepLR, step_size=10, gamma=0.9),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "3f1ea07f-9532-4c85-b961-377ad1ee16fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "import torch\n",
    "import torchmetrics\n",
    "from ptls.frames.supervised import SequenceToTarget\n",
    "from ptls.nn import Head\n",
    "\n",
    "model_supervised = SequenceToTarget(\n",
    "    seq_encoder=model.seq_encoder,\n",
    "    head=torch.nn.Sequential(torch.nn.Linear(1024, 512), \n",
    "                             torch.nn.ReLU(), \n",
    "                             torch.nn.Linear(512, 512), \n",
    "            Head(input_size=512,\n",
    "        use_batch_norm=True,\n",
    "        objective='classification',\n",
    "        num_classes=14,)),\n",
    "    loss=torch.nn.NLLLoss(),\n",
    "    metric_list=torchmetrics.Accuracy(compute_on_step=False),\n",
    "    optimizer_partial=partial(torch.optim.Adam, lr=0.01, weight_decay=1e-5),\n",
    "    lr_scheduler_partial=partial(torch.optim.lr_scheduler.StepLR, step_size=10, gamma=0.9),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faaf7ed2-9782-4439-8a86-32808d4fff8d",
   "metadata": {},
   "source": [
    "### Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "0c2b3322-7818-44a6-adf8-a9322a315b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "import logging\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=50,\n",
    "    limit_val_batches=100,\n",
    "    gpus=[0],\n",
    "    enable_progress_bar=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "1baed641-c4b3-4b5a-80a7-42ffd1eac3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e8672a-97cd-4cb9-9ad4-ad3d1e88d69f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type          | Params\n",
      "------------------------------------------------\n",
      "0 | seq_encoder   | RnnSeqEncoder | 28.9 M\n",
      "1 | head          | Sequential    | 795 K \n",
      "2 | loss          | NLLLoss       | 0     \n",
      "3 | train_metrics | ModuleDict    | 0     \n",
      "4 | valid_metrics | ModuleDict    | 0     \n",
      "5 | test_metrics  | ModuleDict    | 0     \n",
      "------------------------------------------------\n",
      "10.5 M    Trainable params\n",
      "19.2 M    Non-trainable params\n",
      "29.7 M    Total params\n",
      "118.871   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logger.version = 26\n"
     ]
    }
   ],
   "source": [
    "print(f'logger.version = {trainer.logger.version}')\n",
    "trainer.fit(model_supervised, supervised_dm)\n",
    "print(trainer.logged_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "64b7e9fd-84df-4f10-9a0e-8c08dc8ca610",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"coles-sup-emb_pretrained.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea85365-d6fa-4c81-8ab3-5f4cf98b9438",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "81c0849f-92b6-4a6e-9b22-656cf8344397",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"coles-sup-emb_pretrained.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "357a9c4e-778f-4a1d-a5ce-4f7fe3b97045",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:18<00:00,  4.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 29.4 s, sys: 17 s, total: 46.4 s\n",
      "Wall time: 44.8 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import tqdm, torch\n",
    "\n",
    "df_trans = pq.read_table('data/trans_filtered_pretrained.parquet').to_pandas()\n",
    "\n",
    "cols = ['url_host', 'request_cnt', 'part_of_day', 'event_time']\n",
    "\n",
    "for col in tqdm.tqdm(cols):\n",
    "    df_trans[col] = df_trans[col].apply(torch.tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "525553f1-6983-45c3-b6cd-9d9a50ab6c04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "620it [00:21, 28.54it/s]\n",
      "620it [00:12, 50.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 31min 52s, sys: 32.9 s, total: 32min 25s\n",
      "Wall time: 53.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import tqdm\n",
    "from ptls.data_load.datasets import inference_data_loader\n",
    "import numpy as np\n",
    "\n",
    "def pooling_inference(model, dl, device='cuda:0'):\n",
    "    \n",
    "    model.to(device)\n",
    "    X = []\n",
    "    for batch in tqdm.tqdm(dl):\n",
    "        with torch.no_grad():\n",
    "            x = model.seq_encoder.trx_encoder(batch.to(device)).payload\n",
    "            out_max = torch.max(x, dim=1)[0]\n",
    "            out_min = torch.min(x, dim=1)[0]\n",
    "            out_mean = torch.mean(x, dim=1)\n",
    "            out_std = torch.std(x, dim=1)\n",
    "            features = torch.cat([out_max, out_min, out_mean, out_std], dim=1)      \n",
    "            X += [features]\n",
    "    return X\n",
    "\n",
    "def embed_inference(model, dl, device='cuda:0'):\n",
    "    \n",
    "    model.to(device)\n",
    "    X = []\n",
    "    for batch in tqdm.tqdm(dl):\n",
    "        with torch.no_grad():\n",
    "            features = model.seq_encoder(batch.to(device))\n",
    "            X += [features]\n",
    "    return X\n",
    "\n",
    "dl = inference_data_loader(valid_ft, num_workers=0, batch_size=128)\n",
    "X_coles = torch.vstack(embed_inference(model, dl, )).cpu().numpy()\n",
    "X_pool = torch.vstack(pooling_inference(model, dl, )).cpu().numpy()\n",
    "X_embeds = np.concatenate([X_coles, X_pool], axis=1)\n",
    "\n",
    "\n",
    "df_embeds = pd.DataFrame(X_embeds, columns=[f\"embed_{e}\" for e in range(X_embeds.shape[1])])\n",
    "df_embeds['user_id'] = pd.DataFrame(valid_ft)['user_id']\n",
    "df_embeds.to_csv('./data/coles_sup.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34f2f38-af86-417a-904f-4c235e6fa30b",
   "metadata": {},
   "source": [
    "## Downstream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "249e125e-b4f2-458a-8a83-5a897b667e5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.98 s, sys: 810 ms, total: 4.79 s\n",
      "Wall time: 5.51 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import bisect\n",
    "import numpy as np\n",
    "\n",
    "df_embeds = pd.read_csv('./data/coles_sup.csv')\n",
    "df_public = pq.read_table('data/public_train.pqt').to_pandas().sort_values(by='user_id')\n",
    "\n",
    "def age_bucket(x):\n",
    "    return bisect.bisect_left([18,25,35,45,55,65], x)\n",
    "\n",
    "y_age = df_public['age']\n",
    "y_age = np.array(list(map(age_bucket, y_age)))\n",
    "y_gender = np.array(df_public['is_male'].loc[df_public[\"user_id\"].isin(df_embeds[\"user_id\"])])\n",
    "\n",
    "X = df_public\n",
    "X = X.merge(df_embeds, on=\"user_id\", how='inner')\n",
    "del X['user_id'], X['age']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1256856-3585-4b1d-ab90-68d7f2e74847",
   "metadata": {},
   "source": [
    "## Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "f91510b6-e068-4b06-a703-ece8a251280e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.090934\n",
      "0:\tlearn: 0.6619827\ttest: 0.6612122\tbest: 0.6612122 (0)\ttotal: 99.4ms\tremaining: 1m 39s\n",
      "100:\tlearn: 0.4848365\ttest: 0.4832841\tbest: 0.4832841 (100)\ttotal: 8.79s\tremaining: 1m 18s\n",
      "200:\tlearn: 0.4619425\ttest: 0.4761688\tbest: 0.4761688 (200)\ttotal: 18.1s\tremaining: 1m 11s\n",
      "300:\tlearn: 0.4421667\ttest: 0.4726993\tbest: 0.4726993 (300)\ttotal: 27s\tremaining: 1m 2s\n",
      "400:\tlearn: 0.4254223\ttest: 0.4707501\tbest: 0.4707501 (400)\ttotal: 35.4s\tremaining: 52.9s\n",
      "500:\tlearn: 0.4102390\ttest: 0.4699662\tbest: 0.4699662 (500)\ttotal: 43.8s\tremaining: 43.6s\n",
      "600:\tlearn: 0.3963362\ttest: 0.4695110\tbest: 0.4695110 (600)\ttotal: 52.3s\tremaining: 34.7s\n",
      "700:\tlearn: 0.3834829\ttest: 0.4689836\tbest: 0.4689836 (700)\ttotal: 1m\tremaining: 25.9s\n",
      "800:\tlearn: 0.3711384\ttest: 0.4689268\tbest: 0.4689268 (800)\ttotal: 1m 9s\tremaining: 17.2s\n",
      "900:\tlearn: 0.3588902\ttest: 0.4692740\tbest: 0.4689268 (800)\ttotal: 1m 17s\tremaining: 8.54s\n",
      "999:\tlearn: 0.3481730\ttest: 0.4696775\tbest: 0.4689268 (800)\ttotal: 1m 26s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.468926843\n",
      "bestIteration = 800\n",
      "\n",
      "Shrink model to first 801 iterations.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x7f8cd8393eb0>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%time\n",
    "\n",
    "from catboost import CatBoostClassifier, metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "not_na_gender = (y_gender != 'NA') & (y_gender != None)\n",
    "x_train, x_test_gender, y_train, y_test_gender = train_test_split(X.loc[X['is_male']!='NA'].drop('is_male', axis = 1), X['is_male'].loc[X['is_male']!='NA'], test_size = 0.1, random_state = 42)\n",
    "\n",
    "clf_gender = CatBoostClassifier(\n",
    "    iterations=1000,\n",
    "    custom_metric=[metrics.AUC()],\n",
    "    use_best_model=True,\n",
    "    random_seed=42)\n",
    "clf_gender.fit(x_train, y_train, metric_period=100, eval_set=(x_test_gender, y_test_gender))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "36e9073f-a2e5-4380-b3b6-7afbb95503e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINI по полу 0.717\n"
     ]
    }
   ],
   "source": [
    "print(f'GINI по полу {2 * roc_auc_score(y_test_gender.to_numpy(), clf_gender.predict_proba(x_test_gender)[:,1]) - 1:2.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f90007-39ca-413f-bb25-4fb6c4567417",
   "metadata": {},
   "source": [
    "# Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "37c4697a-1ad9-4b11-904a-5d2cae5c0945",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Item wrong length 270000 instead of 79298.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:4\u001b[0m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/ptls-experiments-VBYVncXQ/lib/python3.8/site-packages/pandas/core/frame.py:3496\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3494\u001b[0m \u001b[38;5;66;03m# Do we have a (boolean) 1d indexer?\u001b[39;00m\n\u001b[1;32m   3495\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m com\u001b[38;5;241m.\u001b[39mis_bool_indexer(key):\n\u001b[0;32m-> 3496\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_bool_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3498\u001b[0m \u001b[38;5;66;03m# We are left with two options: a single key, and a collection of keys,\u001b[39;00m\n\u001b[1;32m   3499\u001b[0m \u001b[38;5;66;03m# We interpret tuples as collections only for non-MultiIndex\u001b[39;00m\n\u001b[1;32m   3500\u001b[0m is_single_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_list_like(key)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/ptls-experiments-VBYVncXQ/lib/python3.8/site-packages/pandas/core/frame.py:3543\u001b[0m, in \u001b[0;36mDataFrame._getitem_bool_array\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3537\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   3538\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBoolean Series key will be reindexed to match DataFrame index.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   3539\u001b[0m         \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[1;32m   3540\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m   3541\u001b[0m     )\n\u001b[1;32m   3542\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(key) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex):\n\u001b[0;32m-> 3543\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   3544\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mItem wrong length \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(key)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m instead of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3545\u001b[0m     )\n\u001b[1;32m   3547\u001b[0m \u001b[38;5;66;03m# check_bool_indexer will throw exception if Series key cannot\u001b[39;00m\n\u001b[1;32m   3548\u001b[0m \u001b[38;5;66;03m# be reindexed to match DataFrame rows\u001b[39;00m\n\u001b[1;32m   3549\u001b[0m key \u001b[38;5;241m=\u001b[39m check_bool_indexer(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, key)\n",
      "\u001b[0;31mValueError\u001b[0m: Item wrong length 270000 instead of 79298."
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "not_na_age = ~np.isnan(y_age)\n",
    "x_train, x_test_age, y_train, y_test_age = train_test_split(X[not_na_age], y_age[not_na_age], test_size = 0.1, random_state = 42)\n",
    "\n",
    "clf_age = CatBoostClassifier(iterations=1000,\n",
    "    custom_metric=[metrics.Accuracy()],\n",
    "    use_best_model=True,\n",
    "    random_seed=42)\n",
    "clf_age.fit(x_train, y_train, metric_period=100, eval_set=(x_test_age, y_test_age))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63be1d4-15a0-4c0a-9c5a-5d836a7a24ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test_age, clf_age.predict(x_test_age), \\\n",
    "                            target_names = ['<18', '18-25','25-34', '35-44', '45-54', '55-65', '65+']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83148af4-776b-4bad-8195-cbc282d2a501",
   "metadata": {},
   "outputs": [],
   "source": [
    "0.752 + 2*0.46"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3665984e-8f8a-4ae0-b857-a6afc34a7c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "0.79 + 2*0.49"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ptls-experiments",
   "language": "python",
   "name": "ptls-experiments"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
